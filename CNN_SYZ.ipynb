{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "\n",
        "# DICOM dosyalarının bulunduğu klasör\n",
        "dcm_folder = '/content/drive/MyDrive/Teknofest-2024/Kategori4Sag/11637'\n",
        "\n",
        "# Çıktı dosyalarının kaydedileceği klasör\n",
        "output_folder = '/content/drive/MyDrive/Tekno/denemeler'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# DICOM dosyalarını okuyun ve etiketleyin\n",
        "labels = {}  # Bu sözlük, dosya adlarını etiketlerle eşleştirmek için kullanılacaktır\n",
        "\n",
        "# Burada etiketi DICOM dosyasının metadata'sından okuyabilirsiniz\n",
        "# Örnek olarak, dosya adlarına göre etiketleme yapıyoruz (dosya adlandırma konvansiyonunuza bağlı olarak değişebilir)\n",
        "for root, dirs, files in os.walk(dcm_folder):\n",
        "    for file_name in files:\n",
        "        if file_name.endswith('.dcm'):\n",
        "            file_path = os.path.join(root, file_name)\n",
        "            dicom_data = pydicom.dcmread(file_path)\n",
        "\n",
        "            # Etiket bilgilerini metadata'dan veya dosya adından çıkarın\n",
        "            # Örneğin, dosya adının \"normal\", \"kitle\" veya \"kalsifikasyon\" içerdiğini varsayıyoruz\n",
        "            if 'normal' in file_name:\n",
        "                label = 'normal'\n",
        "            elif 'kitle' in file_name:\n",
        "                label = 'kitle'\n",
        "            elif 'kalsifikasyon' in file_name:\n",
        "                label = 'kalsifikasyon'\n",
        "            else:\n",
        "                continue  # Etiket belirlenemeyen dosyaları atla\n",
        "\n",
        "            labels[file_name] = label\n",
        "\n",
        "print(f\"Toplam {len(labels)} etiketli dosya bulundu.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnIzZ-DtBhuW",
        "outputId": "262ddca1-c742-4f96-feb0-58e27167a7a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Toplam 0 etiketli dosya bulundu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# DICOM dosyalarının bulunduğu klasör\n",
        "dcm_folder = '/content/drive/MyDrive/Teknofest-2024/Kategori1/10267'\n",
        "\n",
        "# Çıktı dosyalarının kaydedileceği klasör\n",
        "output_folder = '/content/drive/MyDrive/Tekno/denemeler/10267'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# DICOM dosyalarını oku ve PNG olarak kaydet\n",
        "for root, dirs, files in os.walk(dcm_folder):\n",
        "    for file_name in files:\n",
        "        if file_name.endswith('.dcm'):\n",
        "            file_path = os.path.join(root, file_name)\n",
        "            dicom_data = pydicom.dcmread(file_path)\n",
        "\n",
        "            # DICOM verilerini numpy array olarak al\n",
        "            image_array = dicom_data.pixel_array\n",
        "\n",
        "            # Görüntüyü normalize et ve uint8 formatına dönüştür\n",
        "            image_array = image_array.astype(float)\n",
        "            image_array = (np.maximum(image_array, 0) / image_array.max()) * 255.0\n",
        "            image_array = np.uint8(image_array)\n",
        "\n",
        "            # Görüntüyü PIL görüntüsüne dönüştür\n",
        "            image = Image.fromarray(image_array)\n",
        "\n",
        "            # PNG olarak kaydet\n",
        "            output_file_path = os.path.join(output_folder, file_name.replace('.dcm', '.png'))\n",
        "            image.save(output_file_path)\n",
        "\n",
        "print(\"Tüm DICOM dosyaları başarıyla PNG formatına dönüştürüldü.\")\n"
      ],
      "metadata": {
        "id": "XiPifqGrBxpx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d6cfaf5-8ae4-4d01-9caf-a85769b83496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tüm DICOM dosyaları başarıyla PNG formatına dönüştürüldü.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ya9uXkepA9cd",
        "outputId": "3a95d3e3-cc20-485d-bf02-70ccba51bd83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydicom\n",
            "  Downloading pydicom-2.4.4-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.4.4\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "#Kütüphane\n",
        "!pip install pydicom\n",
        "!pip install pillow\n",
        "!pip install tensorflow\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Veri yolunu ayarlayın\n",
        "data_dir = '/content/drive/MyDrive/Tekno/denemeler'  # PNG dosyalarının bulunduğu yol\n",
        "classes = ['normal', 'kitle', 'kalsifikasyon']\n",
        "\n",
        "# ImageDataGenerator kullanarak veri ön işleme\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    validation_split=0.2  # %80 eğitim, %20 doğrulama için\n",
        ")\n",
        "\n",
        "# Eğitim verileri\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Doğrulama verileri\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Modeli tanımlayın\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')  # 3 sınıf: normal, kitle, kalsifikasyon\n",
        "])\n",
        "\n",
        "# Modeli derleyin\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Modeli eğitin\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=10  # Eğitim sayısını artırabilirsiniz\n",
        ")\n",
        "\n",
        "# Modeli kaydedin\n",
        "model.save('/content/drive/MyDrive/Tekno/11.06-güncel.h5')\n",
        "\n",
        "# Eğitimin tarihçesini görselleştirin\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Eğitim Doğruluğu')\n",
        "plt.plot(history.history['val_accuracy'], label='Doğrulama Doğruluğu')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Doğruluk')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='Eğitim Kaybı')\n",
        "plt.plot(history.history['val_loss'], label='Doğrulama Kaybı')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Kaybı')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "z5BEAkH_BC6U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4cc2e949-b9e6-4336-b20e-d624d7f074d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 54 images belonging to 28 classes.\n",
            "Found 0 images belonging to 28 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node categorical_crossentropy/softmax_cross_entropy_with_logits defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-54-ad90a753aed0>\", line 60, in <cell line: 60>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5579, in categorical_crossentropy\n\nlogits and labels must be broadcastable: logits_size=[32,3] labels_size=[32,28]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_3059]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-ad90a753aed0>\u001b[0m in \u001b[0;36m<cell line: 60>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Modeli eğitin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node categorical_crossentropy/softmax_cross_entropy_with_logits defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-54-ad90a753aed0>\", line 60, in <cell line: 60>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5579, in categorical_crossentropy\n\nlogits and labels must be broadcastable: logits_size=[32,3] labels_size=[32,28]\n\t [[{{node categorical_crossentropy/softmax_cross_entropy_with_logits}}]] [Op:__inference_train_function_3059]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/Tekno/denemeler'\n",
        "\n",
        "# Ana dizin içeriğini kontrol et\n",
        "print(\"Ana dizin içeriği:\")\n",
        "print(os.listdir(data_dir))\n",
        "\n",
        "# Sınıf klasörlerinin içeriğini kontrol et\n",
        "for class_name in ['normal', 'kitle', 'kalsifikasyon']:\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "    print(f\"{class_name} klasörü içeriği:\")\n",
        "    if os.path.exists(class_dir):\n",
        "        print(os.listdir(class_dir))\n",
        "    else:\n",
        "        print(f\"{class_name} klasörü bulunamadı.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhZRunqrEf7H",
        "outputId": "988e9ccc-98a9-4d9c-ef2a-3c9b47fa0c7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ana dizin içeriği:\n",
            "['.ipynb_checkpoints', '11637', '12443', '11374', '12539', '12614', '12682', '12321', '12369', '12411', '12012', '12065', '12137', '11824', '11866', '11894', '11779', '11718', '11372', '11403', '11436', '11078', '11121', '11180', '10082', '10144', '10210', '10267', 'normal', 'LMLO.png', 'LCC.png', 'umarımsonolur']\n",
            "normal klasörü içeriği:\n",
            "['LCC.png', 'LMLO.png']\n",
            "kitle klasörü içeriği:\n",
            "kitle klasörü bulunamadı.\n",
            "kalsifikasyon klasörü içeriği:\n",
            "kalsifikasyon klasörü bulunamadı.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Veri yolunu ayarlayın\n",
        "data_dir = '/content/drive/MyDrive/Tekno/denemeler'  # PNG dosyalarının bulunduğu yol\n",
        "classes = ['normal', 'kitle', 'kalsifikasyon']\n",
        "\n",
        "# ImageDataGenerator kullanarak veri ön işleme\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    validation_split=0.2  # %80 eğitim, %20 doğrulama için\n",
        ")\n",
        "\n",
        "# Eğitim verileri\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    classes=classes  # Sınıf isimlerini belirleyin\n",
        ")\n",
        "\n",
        "# Doğrulama verileri\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    classes=classes  # Sınıf isimlerini belirleyin\n",
        ")\n",
        "\n",
        "# Örnek sayısını kontrol et\n",
        "print(f\"Training samples: {train_generator.samples}\")\n",
        "print(f\"Validation samples: {validation_generator.samples}\")\n",
        "\n",
        "# steps_per_epoch ve validation_steps değerlerini hesaplayın\n",
        "steps_per_epoch = np.ceil(train_generator.samples / train_generator.batch_size)\n",
        "validation_steps = np.ceil(validation_generator.samples / validation_generator.batch_size)\n",
        "\n",
        "# steps_per_epoch ve validation_steps değerlerini kontrol et\n",
        "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
        "print(f\"Validation steps: {validation_steps}\")\n",
        "\n",
        "# Modeli tanımlayın\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(classes), activation='softmax')  # Sınıf sayısına göre çıktıyı ayarlayın\n",
        "])\n",
        "\n",
        "# Modeli derleyin\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Eğer örnek sayısı sıfır değilse modeli eğitin\n",
        "if train_generator.samples > 0 and validation_generator.samples > 0:\n",
        "    # Modeli eğitin\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=int(steps_per_epoch),\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=int(validation_steps),\n",
        "        epochs=10  # Eğitim sayısını artırabilirsiniz\n",
        "    )\n",
        "\n",
        "    # Modeli kaydedin\n",
        "    model.save('/content/drive/MyDrive/Tekno/11.06-günceltest.h5')\n",
        "\n",
        "    # Eğitimin tarihçesini görselleştirin\n",
        "    plt.plot(history.history['accuracy'], label='Eğitim Doğruluğu')\n",
        "    plt.plot(history.history['val_accuracy'], label='Doğrulama Doğruluğu')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Doğruluk')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(history.history['loss'], label='Eğitim Kaybı')\n",
        "    plt.plot(history.history['val_loss'], label='Doğrulama Kaybı')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Kaybı')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Eğitim veya doğrulama verisi bulunamadı. Lütfen veri dizinini ve sınıf isimlerini kontrol edin.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhAJKH4FDEx0",
        "outputId": "acf986f0-c3af-4f37-d46b-d0315d1cea2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2 images belonging to 3 classes.\n",
            "Found 0 images belonging to 3 classes.\n",
            "Training samples: 2\n",
            "Validation samples: 0\n",
            "Steps per epoch: 1.0\n",
            "Validation steps: 0.0\n",
            "Eğitim veya doğrulama verisi bulunamadı. Lütfen veri dizinini ve sınıf isimlerini kontrol edin.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "\n",
        "# DICOM dosyalarının bulunduğu klasör\n",
        "dcm_folder = '/content/drive/MyDrive/Tekno/10001'\n",
        "\n",
        "# Çıktı dosyalarının kaydedileceği klasör\n",
        "output_folder = '/content/drive/MyDrive/Tekno'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Modeli yükleyin (bu modeli kendiniz eğitmeniz veya önceden eğitilmiş bir model kullanmanız gerekebilir)\n",
        "model_path = '/content/drive/My Drive/path_to_model/my_model.h5'\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Etiketler ve dosya adlarını saklayacak bir sözlük\n",
        "labels = {}\n",
        "\n",
        "# DICOM dosyalarını oku ve tahmin et\n",
        "for root, dirs, files in os.walk(dcm_folder):\n",
        "    for file_name in files:\n",
        "        if file_name.endswith('.dcm'):\n",
        "            file_path = os.path.join(root, file_name)\n",
        "            dicom_data = pydicom.dcmread(file_path)\n",
        "\n",
        "            # DICOM verilerini numpy array olarak al\n",
        "            image_array = dicom_data.pixel_array\n",
        "\n",
        "            # Görüntüyü normalize et ve yeniden boyutlandır\n",
        "            image_array = image_array.astype(float)\n",
        "            image_array = (np.maximum(image_array, 0) / image_array.max()) * 255.0\n",
        "            image_array = np.uint8(image_array)\n",
        "            input_image = cv2.resize(image_array, (224, 224))\n",
        "            input_image = np.expand_dims(input_image, axis=0)\n",
        "            input_image = np.expand_dims(input_image, axis=-1)  # Eğer model RGB bekliyorsa, ekseni çıkarın\n",
        "\n",
        "            # Modeli kullanarak tahmin yap\n",
        "            prediction = model.predict(input_image)\n",
        "            label_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "            # Etiketleri belirle\n",
        "            if label_index == 0:\n",
        "                label = 'normal'\n",
        "            elif label_index == 1:\n",
        "                label = 'kitle'\n",
        "            elif label_index == 2:\n",
        "                label = 'kalsifikasyon'\n",
        "            else:\n",
        "                label = 'unknown'\n",
        "\n",
        "            labels[file_name] = label\n",
        "\n",
        "            # PNG olarak kaydet\n",
        "            label_folder = os.path.join(output_folder, label)\n",
        "            os.makedirs(label_folder, exist_ok=True)\n",
        "            output_file_path = os.path.join(label_folder, file_name.replace('.dcm', '.png'))\n",
        "            Image.fromarray(image_array).save(output_file_path)\n",
        "\n",
        "print(f\"Toplam {len(labels)} dosya işlendi ve etiketlendi.\")\n",
        "\n",
        "# Etiketlenmiş dosya adlarını ve etiketlerini bir dosyaya kaydedin\n",
        "with open('/content/drive/MyDrive/Tekno/labels.txt', 'w') as f:\n",
        "    for file_name, label in labels.items():\n",
        "        f.write(f\"{file_name},{label}\\n\")\n"
      ],
      "metadata": {
        "id": "baj0zga_LbAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "\n",
        "# DICOM dosyalarının bulunduğu klasör\n",
        "dcm_folder = '/content/drive/MyDrive/Tekno/10001'\n",
        "\n",
        "# Çıktı dosyalarının kaydedileceği klasör\n",
        "output_folder = '/content/drive/MyDrive/Tekno'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Modeli yükleyin (bu modeli kendiniz eğitmeniz veya önceden eğitilmiş bir model kullanmanız gerekebilir)\n",
        "model_path = '/content/drive/MyDrive/Tekno/11.06-derleme.h5'\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Etiketler ve dosya adlarını saklayacak bir sözlük\n",
        "labels = {}\n",
        "\n",
        "# DICOM dosyalarını oku ve tahmin et\n",
        "for root, dirs, files in os.walk(dcm_folder):\n",
        "    for file_name in files:\n",
        "        if file_name.endswith('.dcm'):\n",
        "            file_path = os.path.join(root, file_name)\n",
        "            dicom_data = pydicom.dcmread(file_path)\n",
        "\n",
        "            # DICOM verilerini numpy array olarak al\n",
        "            image_array = dicom_data.pixel_array\n",
        "            image_path = \"/content/drive/MyDrive/Tekno/LMLO.png\"\n",
        "            input_image = Image.open(image_path)\n",
        "\n",
        "            # Görüntüyü siyah beyaz formatına dönüştür\n",
        "            input_image_gray = input_image.convert(\"L\")  # \"L\" modu siyah beyaz formatıdır\n",
        "            # Görüntüyü RGB formatına dönüştür\n",
        "            input_image_rgb = input_image_gray.convert('RGB')\n",
        "\n",
        "\n",
        "\n",
        "            # Görüntüyü normalize et ve yeniden boyutlandır\n",
        "            image_array = image_array.astype(float)\n",
        "            image_array = (np.maximum(image_array, 0) / image_array.max()) * 255.0\n",
        "            image_array = np.uint8(image_array)\n",
        "            input_image = cv2.resize(image_array, (224, 224))\n",
        "            input_image = np.expand_dims(input_image, axis=0)\n",
        "            input_image = np.expand_dims(input_image, axis=-1)  # Eğer model RGB bekliyorsa, ekseni çıkarın\n",
        "\n",
        "            # Modeli kullanarak tahmin yap\n",
        "            prediction = model.predict(input_image)\n",
        "            label_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "            # Etiketleri belirle\n",
        "            if label_index == 0:\n",
        "                label = 'normal'\n",
        "            elif label_index == 1:\n",
        "                label = 'kitle'\n",
        "            elif label_index == 2:\n",
        "                label = 'kalsifikasyon'\n",
        "            else:\n",
        "                label = 'unknown'\n",
        "\n",
        "            labels[file_name] = label\n",
        "\n",
        "            # PNG olarak kaydet\n",
        "            label_folder = os.path.join(output_folder, label)\n",
        "            os.makedirs(label_folder, exist_ok=True)\n",
        "            output_file_path = os.path.join(label_folder, file_name.replace('.dcm', '.png'))\n",
        "            Image.fromarray(image_array).save(output_file_path)\n",
        "\n",
        "print(f\"Toplam {len(labels)} dosya işlendi ve etiketlendi.\")\n",
        "\n",
        "# Etiketlenmiş dosya adlarını ve etiketlerini bir dosyaya kaydedin\n",
        "with open('/content/drive/MyDrive/Tekno/labels.txt', 'w') as f:\n",
        "    for file_name, label in labels.items():\n",
        "        f.write(f\"{file_name},{label}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wuAp74QMTHAU",
        "outputId": "f4e7e4c8-c95f-437a-f703-392b380efd50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_35' (type Sequential).\n    \n    Input 0 of layer \"conv2d_105\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 224, 224, 1)\n    \n    Call arguments received by layer 'sequential_35' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 224, 224, 1), dtype=uint8)\n      • training=False\n      • mask=None\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a783a29208fd>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# Modeli kullanarak tahmin yap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mlabel_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_35' (type Sequential).\n    \n    Input 0 of layer \"conv2d_105\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 224, 224, 1)\n    \n    Call arguments received by layer 'sequential_35' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 224, 224, 1), dtype=uint8)\n      • training=False\n      • mask=None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "\n",
        "# DICOM dosyalarının bulunduğu klasör\n",
        "dcm_folder = '/content/drive/MyDrive/Teknofest-2024/Kategori5Sol/12471'\n",
        "\n",
        "# Çıktı dosyalarının kaydedileceği klasör\n",
        "output_folder = '/content/drive/MyDrive/Tekno'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Modeli yükleyin (bu modeli kendiniz eğitmeniz veya önceden eğitilmiş bir model kullanmanız gerekebilir)\n",
        "model_path = '/content/drive/MyDrive/Tekno/11.06-derleme.h5'\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Etiketler ve dosya adlarını saklayacak bir sözlük\n",
        "labels = {}\n",
        "\n",
        "# DICOM dosyalarını oku ve tahmin et\n",
        "for root, dirs, files in os.walk(dcm_folder):\n",
        "    for file_name in files:\n",
        "        if file_name.endswith('.dcm'):\n",
        "            file_path = os.path.join(root, file_name)\n",
        "            dicom_data = pydicom.dcmread(file_path)\n",
        "\n",
        "            # DICOM verilerini numpy array olarak al\n",
        "            image_array = dicom_data.pixel_array\n",
        "\n",
        "            # Görüntüyü normalize et ve yeniden boyutlandır\n",
        "            image_array = image_array.astype(float)\n",
        "            image_array = (np.maximum(image_array, 0) / image_array.max()) * 255.0\n",
        "            image_array = np.uint8(image_array)\n",
        "\n",
        "            # Görüntüyü PIL görüntüsüne dönüştür\n",
        "            input_image_gray = Image.fromarray(image_array)\n",
        "            input_image_rgb = input_image_gray.convert(\"RGB\")\n",
        "\n",
        "            # Görüntüyü modelin beklediği boyutlara yeniden boyutlandır\n",
        "            input_image_resized = input_image_rgb.resize((224, 224))\n",
        "            input_image_resized = np.array(input_image_resized)\n",
        "            input_image_resized = np.expand_dims(input_image_resized, axis=0)  # Batch boyutu ekleyin\n",
        "\n",
        "            # Modeli kullanarak tahmin yap\n",
        "            prediction = model.predict(input_image_resized)\n",
        "            label_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "            # Etiketleri belirle\n",
        "            if label_index == 0:\n",
        "                label = 'normal'\n",
        "            elif label_index == 1:\n",
        "                label = 'kitle'\n",
        "            elif label_index == 2:\n",
        "                label = 'kalsifikasyon'\n",
        "            else:\n",
        "                label = 'unknown'\n",
        "\n",
        "            labels[file_name] = label\n",
        "\n",
        "            # PNG olarak kaydet\n",
        "            label_folder = os.path.join(output_folder, label)\n",
        "            os.makedirs(label_folder, exist_ok=True)\n",
        "            output_file_path = os.path.join(label_folder, file_name.replace('.dcm', '.png'))\n",
        "            Image.fromarray(image_array).save(output_file_path)\n",
        "\n",
        "print(f\"Toplam {len(labels)} dosya işlendi ve etiketlendi.\")\n",
        "\n",
        "# Etiketlenmiş dosya adlarını ve etiketlerini bir dosyaya kaydedin\n",
        "with open('/content/drive/MyDrive/Tekno/labels.txt', 'w') as f:\n",
        "    for file_name, label in labels.items():\n",
        "        f.write(f\"{file_name},{label}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c_-hgqxUdTc",
        "outputId": "5600a363-d4b9-43ad-cd48-259975fd3487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 184ms/step\n",
            "1/1 [==============================] - 0s 111ms/step\n",
            "Toplam 2 dosya işlendi ve etiketlendi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "\n",
        "# DICOM dosyalarının bulunduğu klasör\n",
        "dcm_folder = '/content/drive/MyDrive/Teknofest-2024/Kategori5Sol/12471'\n",
        "\n",
        "# Çıktı dosyalarının kaydedileceği klasör\n",
        "output_folder = '/content/drive/MyDrive/Tekno'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Modeli yükleyin (bu modeli kendiniz eğitmeniz veya önceden eğitilmiş bir model kullanmanız gerekebilir)\n",
        "model_path = '/content/drive/MyDrive/Tekno/11.06-derleme.h5'\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Etiketler ve dosya adlarını saklayacak bir sözlük\n",
        "labels = {}\n",
        "\n",
        "# DICOM dosyalarını oku ve tahmin et\n",
        "for root, dirs, files in os.walk(dcm_folder):\n",
        "    for file_name in files:\n",
        "        if file_name.endswith('.dcm'):\n",
        "            file_path = os.path.join(root, file_name)\n",
        "            dicom_data = pydicom.dcmread(file_path)\n",
        "\n",
        "            # DICOM verilerini numpy array olarak al\n",
        "            image_array = dicom_data.pixel_array\n",
        "\n",
        "            # Görüntüyü normalize et ve yeniden boyutlandır\n",
        "            image_array = image_array.astype(float)\n",
        "            image_array = (np.maximum(image_array, 0) / image_array.max()) * 255.0\n",
        "            image_array = np.uint8(image_array)\n",
        "\n",
        "            # Görüntüyü PIL görüntüsüne dönüştür\n",
        "            input_image_gray = Image.fromarray(image_array)\n",
        "            input_image_rgb = input_image_gray.convert(\"RGB\")\n",
        "\n",
        "            # Görüntüyü modelin beklediği boyutlara yeniden boyutlandır\n",
        "            input_image_resized = input_image_rgb.resize((224, 224))\n",
        "            input_image_resized = np.array(input_image_resized)\n",
        "            input_image_resized = np.expand_dims(input_image_resized, axis=0)  # Batch boyutu ekleyin\n",
        "\n",
        "            # Modeli kullanarak tahmin yap\n",
        "            prediction = model.predict(input_image_resized)\n",
        "            label_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "            # Etiketleri belirle\n",
        "            if label_index == 0:\n",
        "                label = 'normal'\n",
        "            elif label_index == 1:\n",
        "                label = 'kitle'\n",
        "            elif label_index == 2:\n",
        "                label = 'kalsifikasyon'\n",
        "            else:\n",
        "                label = 'unknown'\n",
        "\n",
        "            labels[file_name] = label\n",
        "\n",
        "            # PNG olarak kaydet\n",
        "            label_folder = os.path.join(output_folder, label)\n",
        "            os.makedirs(label_folder, exist_ok=True)\n",
        "            output_file_path = os.path.join(label_folder, file_name.replace('.dcm', '.png'))\n",
        "            Image.fromarray(image_array).save(output_file_path)\n",
        "\n",
        "print(f\"Toplam {len(labels)} dosya işlendi ve etiketlendi.\")\n",
        "\n",
        "# Etiketlenmiş dosya adlarını ve etiketlerini bir dosyaya kaydedin\n",
        "with open('/content/drive/MyDrive/Tekno/labels.txt', 'w') as f:\n",
        "    for file_name, label in labels.items():\n",
        "        f.write(f\"{file_name},{label}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEqgUfM6WcIH",
        "outputId": "94feb454-97e5-4f05-b378-76782daabbe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 213ms/step\n",
            "1/1 [==============================] - 0s 217ms/step\n",
            "Toplam 2 dosya işlendi ve etiketlendi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "\n",
        "# DICOM dosyalarının bulunduğu klasör\n",
        "dcm_folder = '/content/drive/MyDrive/Teknofest-2024/Kategori5Sol/12471'\n",
        "\n",
        "# Çıktı dosyalarının kaydedileceği klasör\n",
        "output_folder = '/content/drive/MyDrive/Tekno'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Modeli yükleyin (bu modeli kendiniz eğitmeniz veya önceden eğitilmiş bir model kullanmanız gerekebilir)\n",
        "model_path = '/content/drive/MyDrive/Tekno/11.06-derleme.h5'\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Etiketler ve dosya adlarını saklayacak bir sözlük\n",
        "labels = {}\n",
        "\n",
        "# Görüntü ve etiketler listesi\n",
        "images_with_labels = []\n",
        "\n",
        "# DICOM dosyalarını oku ve tahmin et\n",
        "for root, dirs, files in os.walk(dcm_folder):\n",
        "    for file_name in files:\n",
        "        if file_name.endswith('.dcm'):\n",
        "            file_path = os.path.join(root, file_name)\n",
        "            dicom_data = pydicom.dcmread(file_path)\n",
        "\n",
        "            # DICOM verilerini numpy array olarak al\n",
        "            image_array = dicom_data.pixel_array\n",
        "\n",
        "            # Görüntüyü normalize et ve yeniden boyutlandır\n",
        "            image_array = image_array.astype(float)\n",
        "            image_array = (np.maximum(image_array, 0) / image_array.max()) * 255.0\n",
        "            image_array = np.uint8(image_array)\n",
        "\n",
        "            # Görüntüyü PIL görüntüsüne dönüştür\n",
        "            input_image_gray = Image.fromarray(image_array)\n",
        "            input_image_rgb = input_image_gray.convert(\"RGB\")\n",
        "\n",
        "            # Görüntüyü modelin beklediği boyutlara yeniden boyutlandır\n",
        "            input_image_resized = input_image_rgb.resize((224, 224))\n",
        "            input_image_resized = np.array(input_image_resized)\n",
        "            input_image_resized = np.expand_dims(input_image_resized, axis=0)  # Batch boyutu ekleyin\n",
        "\n",
        "            # Modeli kullanarak tahmin yap\n",
        "            prediction = model.predict(input_image_resized)\n",
        "            label_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "            # Etiketleri belirle\n",
        "            if label_index == 0:\n",
        "                label = 'normal'\n",
        "            elif label_index == 1:\n",
        "                label = 'kitle'\n",
        "            elif label_index == 2:\n",
        "                label = 'kalsifikasyon'\n",
        "            else:\n",
        "                label = 'unknown'\n",
        "\n",
        "            labels[file_name] = label\n",
        "\n",
        "            # PNG olarak kaydet\n",
        "            label_folder = os.path.join(output_folder, label)\n",
        "            os.makedirs(label_folder, exist_ok=True)\n",
        "            output_file_path = os.path.join(label_folder, file_name.replace('.dcm', '.png'))\n",
        "            Image.fromarray(image_array).save(output_file_path)\n",
        "\n",
        "            # Görüntüyü ve etiketi listeye ekle\n",
        "            images_with_labels.append((output_file_path, label))\n",
        "\n",
        "print(f\"Toplam {len(labels)} dosya işlendi ve etiketlendi.\")\n",
        "\n",
        "# Etiketlenmiş dosya adlarını ve etiketlerini bir dosyaya kaydedin\n",
        "with open('/content/drive/MyDrive/Tekno/labels.txt', 'w') as f:\n",
        "    for file_name, label in labels.items():\n",
        "        f.write(f\"{file_name},{label}\\n\")\n",
        "\n",
        "# Görüntüler ve etiketler listesini yazdır\n",
        "for image_path, label in images_with_labels:\n",
        "    print(f\"Görüntü: {image_path}, Etiket: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW4CAdqKWzON",
        "outputId": "a515091e-54ad-4b26-d313-873757752d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 186ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "Toplam 2 dosya işlendi ve etiketlendi.\n",
            "Görüntü: /content/drive/MyDrive/Tekno/kalsifikasyon/LMLO.png, Etiket: kalsifikasyon\n",
            "Görüntü: /content/drive/MyDrive/Tekno/kalsifikasyon/LCC.png, Etiket: kalsifikasyon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "\n",
        "# DICOM dosyalarının bulunduğu klasör\n",
        "dcm_folder = '/content/drive/MyDrive/Teknofest-2024/Kategori5Sol/12471'\n",
        "\n",
        "# Çıktı dosyalarının kaydedileceği klasör\n",
        "output_folder = '/content/drive/MyDrive/Tekno'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Modeli yükleyin (bu modeli kendiniz eğitmeniz veya önceden eğitilmiş bir model kullanmanız gerekebilir)\n",
        "model_path = '/content/drive/MyDrive/Tekno/11.06-derleme.h5'\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Etiketler ve dosya adlarını saklayacak bir sözlük\n",
        "labels = {}\n",
        "\n",
        "# Görüntü ve etiketler listesi\n",
        "images_with_labels = []\n",
        "\n",
        "# DICOM dosyalarını oku ve tahmin et\n",
        "for root, dirs, files in os.walk(dcm_folder):\n",
        "    for file_name in files:\n",
        "        if file_name.endswith('.dcm'):\n",
        "            file_path = os.path.join(root, file_name)\n",
        "            dicom_data = pydicom.dcmread(file_path)\n",
        "\n",
        "            # DICOM verilerini numpy array olarak al\n",
        "            image_array = dicom_data.pixel_array\n",
        "\n",
        "            # Görüntüyü normalize et ve yeniden boyutlandır\n",
        "            image_array = image_array.astype(float)\n",
        "            image_array = (np.maximum(image_array, 0) / image_array.max()) * 255.0\n",
        "            image_array = np.uint8(image_array)\n",
        "\n",
        "            # Görüntüyü PIL görüntüsüne dönüştür\n",
        "            input_image_gray = Image.fromarray(image_array)\n",
        "            input_image_rgb = input_image_gray.convert(\"RGB\")\n",
        "\n",
        "            # Görüntüyü modelin beklediği boyutlara yeniden boyutlandır\n",
        "            input_image_resized = input_image_rgb.resize((224, 224))\n",
        "            input_image_resized = np.array(input_image_resized)\n",
        "            input_image_resized = np.expand_dims(input_image_resized, axis=0)  # Batch boyutu ekleyin\n",
        "\n",
        "            # Modeli kullanarak tahmin yap\n",
        "            prediction = model.predict(input_image_resized)\n",
        "            label_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "            # Etiketleri belirle\n",
        "            if label_index == 0:\n",
        "                label = 'normal'\n",
        "            elif label_index == 1:\n",
        "                label = 'kitle'\n",
        "            elif label_index == 2:\n",
        "                label = 'kalsifikasyon'\n",
        "            else:\n",
        "                label = 'unknown'\n",
        "\n",
        "            labels[file_name] = label\n",
        "\n",
        "            # PNG olarak kaydet\n",
        "            label_folder = os.path.join(output_folder, label)\n",
        "            os.makedirs(label_folder, exist_ok=True)\n",
        "            output_file_path = os.path.join(label_folder, file_name.replace('.dcm', '.png'))\n",
        "            Image.fromarray(image_array).save(output_file_path)\n",
        "\n",
        "            # Görüntüyü ve etiketi listeye ekle\n",
        "            images_with_labels.append((output_file_path, label))\n",
        "\n",
        "print(f\"Toplam {len(labels)} dosya işlendi ve etiketlendi.\")\n",
        "\n",
        "# Etiketlenmiş dosya adlarını ve etiketlerini bir dosyaya kaydedin\n",
        "with open('/content/drive/MyDrive/Tekno/labels.txt', 'w') as f:\n",
        "    for file_name, label in labels.items():\n",
        "        f.write(f\"{file_name},{label}\\n\")\n",
        "\n",
        "# Görüntüler ve etiketler listesini yazdır\n",
        "for image_path, label in images_with_labels:\n",
        "    print(f\"Görüntü: {image_path}, Etiket: {label}\")\n",
        "\n",
        "# Görüntüler ve etiketler listesini işleyin ve etiketli görüntüleri kaydedin\n",
        "for image_path, label in images_with_labels:\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Etiketin görüntüye eklenmesi\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    bottomLeftCornerOfText = (10, 30)\n",
        "    fontScale = 1\n",
        "    fontColor = (48, 48, 48)\n",
        "    lineType = 2\n",
        "\n",
        "    cv2.putText(image, label,\n",
        "                bottomLeftCornerOfText,\n",
        "                font,\n",
        "                fontScale,\n",
        "                fontColor,\n",
        "                lineType)\n",
        "\n",
        "    # Etiketlenmiş görüntüyü kaydet\n",
        "    output_labeled_path = os.path.join(output_folder, f\"labeled_{os.path.basename(image_path)}\")\n",
        "    cv2.imwrite(output_labeled_path, image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1GLZA89XUFw",
        "outputId": "c38d86b9-ee3b-44dd-9d65-3327b484a285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7f8167520> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 215ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "Toplam 2 dosya işlendi ve etiketlendi.\n",
            "Görüntü: /content/drive/MyDrive/Tekno/kalsifikasyon/LMLO.png, Etiket: kalsifikasyon\n",
            "Görüntü: /content/drive/MyDrive/Tekno/kalsifikasyon/LCC.png, Etiket: kalsifikasyon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import tensorflow as tf\n",
        "\n",
        "# DICOM dosyalarının bulunduğu klasör\n",
        "dcm_folder = '/content/drive/MyDrive/Teknofest-2024/Kategori5Sol/12471'\n",
        "\n",
        "# Çıktı dosyalarının kaydedileceği klasör\n",
        "output_folder = '/content/drive/MyDrive/Tekno/10001'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Modeli yükleyin (bu modeli kendiniz eğitmeniz veya önceden eğitilmiş bir model kullanmanız gerekebilir)\n",
        "model_path = '/content/drive/MyDrive/Tekno/11.06-derleme.h5'\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Etiketler ve dosya adlarını saklayacak bir sözlük\n",
        "labels = {}\n",
        "\n",
        "# Görüntü ve etiketler listesi\n",
        "images_with_labels = []\n",
        "\n",
        "# DICOM dosyalarını oku ve tahmin et\n",
        "for root, dirs, files in os.walk(dcm_folder):\n",
        "    for file_name in files:\n",
        "        if file_name.endswith('.dcm'):\n",
        "            file_path = os.path.join(root, file_name)\n",
        "            dicom_data = pydicom.dcmread(file_path)\n",
        "\n",
        "            # DICOM verilerini numpy array olarak al\n",
        "            image_array = dicom_data.pixel_array\n",
        "\n",
        "            # Görüntüyü normalize et ve yeniden boyutlandır\n",
        "            image_array = image_array.astype(float)\n",
        "            image_array = (np.maximum(image_array, 0) / image_array.max()) * 255.0\n",
        "            image_array = np.uint8(image_array)\n",
        "\n",
        "            # Görüntüyü RGB formata dönüştür\n",
        "            input_image_rgb = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Görüntüyü modelin beklediği boyutlara yeniden boyutlandır\n",
        "            input_image_resized = cv2.resize(input_image_rgb, (224, 224))\n",
        "            input_image_resized = np.expand_dims(input_image_resized, axis=0)  # Batch boyutu ekleyin\n",
        "\n",
        "            # Modeli kullanarak tahmin yap\n",
        "            prediction = model.predict(input_image_resized)\n",
        "            label_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "            # Etiketleri belirle\n",
        "            if label_index == 0:\n",
        "                label = 'normal'\n",
        "            elif label_index == 1:\n",
        "                label = 'kitle'\n",
        "            elif label_index == 2:\n",
        "                label = 'kalsifikasyon'\n",
        "            else:\n",
        "                label = 'unknown'\n",
        "\n",
        "            labels[file_name] = label\n",
        "\n",
        "            # PNG olarak kaydet\n",
        "            label_folder = os.path.join(output_folder, label)\n",
        "            os.makedirs(label_folder, exist_ok=True)\n",
        "            output_file_path = os.path.join(label_folder, file_name.replace('.dcm', '.png'))\n",
        "            cv2.imwrite(output_file_path, image_array)\n",
        "\n",
        "            # Görüntüyü ve etiketi listeye ekle\n",
        "            images_with_labels.append((output_file_path, label))\n",
        "\n",
        "print(f\"Toplam {len(labels)} dosya işlendi ve etiketlendi.\")\n",
        "\n",
        "# Görüntüler ve etiketler listesini işleyin ve etiketli görüntüleri kaydedin\n",
        "for image_path, label in images_with_labels:\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Sınırlayıcı kutuyu çizin\n",
        "    if label != 'unknown':\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        fontScale = 1\n",
        "        fontColor = (255, 255, 255)\n",
        "        lineType = 2\n",
        "        thickness = 2\n",
        "\n",
        "        # Sınırlayıcı kutunun koordinatlarını alın\n",
        "        contours, _ = cv2.findContours(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        for contour in contours:\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), thickness)\n",
        "            cv2.putText(image, label, (x, y - 10), font, fontScale, fontColor, lineType)\n",
        "\n",
        "    # Etiketlenmiş görüntüyü kaydedin\n",
        "    output_file_path = os.path.join(label_folder, os.path.basename(image_path))\n",
        "    cv2.imwrite(output_file_path, image)\n",
        "\n",
        "print(\"Etiketlenmiş görüntüler başarıyla kaydedildi.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pOGS3s1YPq2",
        "outputId": "9cc4b00c-cad3-44b7-aa59-de3a41f6e43a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe7d4c04af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 186ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "Toplam 2 dosya işlendi ve etiketlendi.\n",
            "Etiketlenmiş görüntüler başarıyla kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Çalışan KOD\n",
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import tensorflow as tf\n",
        "import csv\n",
        "\n",
        "labels = {}\n",
        "\n",
        "label_coordinates = []\n",
        "\n",
        "# DICOM dosyalarının bulunduğu klasör\n",
        "dcm_folder = '/content/drive/MyDrive/Teknofest-2024/Kategori5Sag/12431'\n",
        "\n",
        "kategori = 'Kategori5'\n",
        "kategorinum = '12431'\n",
        "\n",
        "# Çıktı dosyalarının kaydedileceği klasör\n",
        "output_folder = '/content/drive/MyDrive/Tekno/denemeler/umarımsonolur/12431'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Modeli yükleyin (bu modeli kendiniz eğitmeniz veya önceden eğitilmiş bir model kullanmanız gerekebilir)\n",
        "model_path = '/content/drive/MyDrive/Tekno/11.06-derleme.h5'\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# Görüntü ve etiketler listesi\n",
        "images_with_labels = []\n",
        "\n",
        "# DICOM dosyalarını oku ve tahmin et\n",
        "for root, dirs, files in os.walk(dcm_folder):\n",
        "    for file_name in files:\n",
        "        if file_name.endswith('.dcm'):\n",
        "            file_path = os.path.join(root, file_name)\n",
        "            dicom_data = pydicom.dcmread(file_path)\n",
        "\n",
        "            # DICOM verilerini numpy array olarak al\n",
        "            image_array = dicom_data.pixel_array\n",
        "\n",
        "            # Görüntüyü normalize et ve yeniden boyutlandır\n",
        "            image_array = image_array.astype(float)\n",
        "            image_array = (np.maximum(image_array, 0) / image_array.max()) * 255.0\n",
        "            image_array = np.uint8(image_array)\n",
        "\n",
        "            # Görüntüyü RGB formata dönüştür\n",
        "            input_image_rgb = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Görüntüyü modelin beklediği boyutlara yeniden boyutlandır\n",
        "            input_image_resized = cv2.resize(input_image_rgb, (224, 224))\n",
        "            input_image_resized = np.expand_dims(input_image_resized, axis=0)  # Batch boyutu ekleyin\n",
        "\n",
        "            # Modeli kullanarak tahmin yap\n",
        "            prediction = model.predict(input_image_resized)\n",
        "            label_index = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "            # Etiketleri belirle\n",
        "            if label_index == 0:\n",
        "                label = 'Normal'\n",
        "            elif label_index == 1:\n",
        "                label = 'Kitle'\n",
        "            elif label_index == 2:\n",
        "                label = 'Kalsifikasyon'\n",
        "            else:\n",
        "                label = 'Bulunamadı'\n",
        "\n",
        "            # PNG olarak kaydet\n",
        "            label_folder = os.path.join(output_folder, label)\n",
        "            os.makedirs(label_folder, exist_ok=True)\n",
        "            output_file_path = os.path.join(label_folder, file_name.replace('.dcm', '.png'))\n",
        "            Image.fromarray(image_array).save(output_file_path)\n",
        "\n",
        "            # Görüntüyü ve etiketi listeye ekle\n",
        "            images_with_labels.append((output_file_path, label))\n",
        "\n",
        "print(f\"Toplam {len(images_with_labels)} dosya işlendi ve etiketlendi.\")\n",
        "\n",
        "# Görüntüler ve etiketler listesini yazdır\n",
        "for image_path, label in images_with_labels:\n",
        "  print(f\"Görüntü: {image_path}, Etiket: {label}\")\n",
        "\n",
        "# Görüntüler ve etiketler listesini işleyin ve etiketli görüntüleri kaydedin\n",
        "for image_path, label in images_with_labels:\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Sınırlayıcı kutuyu çizin\n",
        "    if label != 'Bulunamadı':\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "        fontScale = 1.50\n",
        "        fontColor = (48, 48, 48)\n",
        "        lineType = 2\n",
        "        thickness = 2\n",
        "        #print(label)\n",
        "\n",
        "        # Sınırlayıcı kutunun koordinatlarını alın\n",
        "        # Etiketin görüntüye eklenmesi\n",
        "        bottomLeftCornerOfText = (10, 50)\n",
        "        contours, _ = cv2.findContours(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        for contour in contours:\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            #cv2.rectangle(image, (x, y), (x + w, y + h), (48, 255, 48), thickness)\n",
        "            cv2.putText(image, label, bottomLeftCornerOfText, font, fontScale, fontColor, lineType)\n",
        "            coordinate_string = f\"{x},{y};{x},{y + h};{x + w},{y + h};{x + w},{y}\"\n",
        "            label_coordinates.append((file_name, label, coordinate_string))\n",
        "\n",
        "    # Etiketlenmiş görüntüyü kaydedin\n",
        "    output_file_path = os.path.join(output_folder, os.path.basename(image_path))\n",
        "    cv2.imwrite(output_file_path, image)\n",
        "\n",
        "    labels[file_name] = label\n",
        "\n",
        "    # Etiketlenmiş görüntüyü kaydet\n",
        "    output_labeled_path = os.path.join(output_folder, f\"labeled_{os.path.basename(image_path)}\")\n",
        "    cv2.imwrite(output_labeled_path, image)\n",
        "\n",
        "    # Modeli kullanarak tahmin yap\n",
        "    prediction = model.predict(input_image_resized)[0]\n",
        "\n",
        "    item = label_coordinates\n",
        "csv_file_path = '/content/drive/MyDrive/Tekno/labels.csv'\n",
        "file_exists = os.path.isfile(csv_file_path)\n",
        "\n",
        "with open(csv_file_path, 'a', newline='', encoding='utf-8') as csvfile:  # 'a' modunda açarak dosyaya ekleme yapıyoruz\n",
        "    csvwriter = csv.writer(csvfile)\n",
        "    if not file_exists:\n",
        "        csvwriter.writerow([\"KATEGORİ\", \"HASTA ID\", \"DOSYA ADI\", \"ETİKET ADI\", \"ETİKET KOORDİNATLARI\"])  # Başlıkları yaz\n",
        "    for item in label_coordinates:\n",
        "        for file_name, label in labels.items():\n",
        "          print(\"Konum Değeleri: \" + item[2])  # Değerleri görmek için\n",
        "    csvwriter.writerow([kategori, kategorinum, file_name, label, item[2]])\n",
        "\n",
        "print(f\"Toplam {len(labels)} dosya işlendi ve etiketlendi.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJeoCj8vbC6y",
        "outputId": "a6211c57-8bef-4a21-f451-784cb60b66bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 569ms/step\n",
            "1/1 [==============================] - 0s 158ms/step\n",
            "Toplam 2 dosya işlendi ve etiketlendi.\n",
            "Görüntü: /content/drive/MyDrive/Tekno/denemeler/umarımsonolur/12431/Kitle/RCC.png, Etiket: Kitle\n",
            "Görüntü: /content/drive/MyDrive/Tekno/denemeler/umarımsonolur/12431/Kitle/RMLO.png, Etiket: Kitle\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 221ms/step\n",
            "Konum Değeleri: 0,0;0,2964;2364,2964;2364,0\n",
            "Konum Değeleri: 0,0;0,2964;2364,2964;2364,0\n",
            "Toplam 1 dosya işlendi ve etiketlendi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydicom\n",
        "!pip install pillow\n",
        "!pip install tensorflow\n",
        "!pip install scikit-learn\n",
        "!pip install opencv-python-headless"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cj5adZf6MS4J",
        "outputId": "58ffbd02-e818-4330-d76e-84093e5bb214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.10/dist-packages (2.4.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.82)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# DICOM dosyalarının bulunduğu klasör\n",
        "dcm_folder = '/content/drive/MyDrive/Tekno/10001'\n",
        "\n",
        "# Çıktı dosyalarının kaydedileceği klasör\n",
        "output_folder = '/content/drive/MyDrive/Tekno'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# DICOM dosyalarını PNG formatına dönüştür ve etiketli klasörlere kaydet\n",
        "for root, dirs, files in os.walk(dcm_folder):\n",
        "    for file_name in files:\n",
        "        if file_name.endswith('.dcm'):\n",
        "            file_path = os.path.join(root, file_name)\n",
        "            dicom_data = pydicom.dcmread(file_path)\n",
        "\n",
        "            # DICOM verilerini numpy array olarak al\n",
        "            image_array = dicom_data.pixel_array\n",
        "\n",
        "            # Görüntüyü normalize et (isteğe bağlı)\n",
        "            image_array = image_array.astype(float)\n",
        "            image_array = (np.maximum(image_array, 0) / image_array.max()) * 255.0\n",
        "            image_array = np.uint8(image_array)\n",
        "\n",
        "            # PIL kullanarak görüntü oluştur\n",
        "            image = Image.fromarray(image_array)\n",
        "\n",
        "            # Etikete göre klasör oluştur ve PNG olarak kaydet\n",
        "            if 'normal' in file_name.lower():\n",
        "                label = 'normal'\n",
        "            elif 'kitle' in file_name.lower():\n",
        "                label = 'kitle'\n",
        "            elif 'kalsifikasyon' in file_name.lower():\n",
        "                label = 'kalsifikasyon'\n",
        "            else:\n",
        "                label = 'unknown'  # Tanımlanamayan dosyalar\n",
        "\n",
        "            label_folder = os.path.join(output_folder, label)\n",
        "            os.makedirs(label_folder, exist_ok=True)\n",
        "            output_file_path = os.path.join(label_folder, file_name.replace('.dcm', '.png'))\n",
        "            image.save(output_file_path)\n",
        "\n",
        "print(\"Tüm dosyalar başarıyla PNG formatına dönüştürüldü.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4Me62_kMVyK",
        "outputId": "d983bb74-78c3-4b07-a303-8e143ece03b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tüm dosyalar başarıyla PNG formatına dönüştürüldü.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Veri yolunu ayarlayın\n",
        "data_dir = output_folder  # PNG dosyalarının bulunduğu yol\n",
        "classes = ['normal', 'kitle', 'kalsifikasyon']\n",
        "\n",
        "# ImageDataGenerator kullanarak veri ön işleme\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    validation_split=0.2  # %80 eğitim, %20 doğrulama için\n",
        ")\n",
        "\n",
        "# Eğitim verileri\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Doğrulama verileri\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Modeli tanımlayın\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')  # 3 sınıf: normal, kitle, kalsifikasyon\n",
        "])\n",
        "\n",
        "# Modeli derleyin\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "train_data_size = len(train_generator)\n",
        "\n",
        "# Önerilen batch_size değeri\n",
        "recommended_batch_size = 32\n",
        "\n",
        "# batch_size değerini ayarlayın\n",
        "batch_size = min(recommended_batch_size, train_data_size)\n",
        "\n",
        "steps_per_epoch = train_data_size // batch_size\n",
        "\n",
        "# Modeli eğitin\n",
        "history = model.fit(\n",
        "  train_generator,\n",
        "    steps_per_epoch=train_data_size // batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,  # Doğrulama verisini belirtin\n",
        "    validation_steps=validation_data // batch_size\n",
        "\n",
        ")\n",
        "\n",
        "# Modeli kaydedin\n",
        "model.save('/content/drive/MyDrive/Tekno/mammogram_cnn_model.h5')\n",
        "\n",
        "# Eğitimin tarihçesini görselleştirin\n",
        "plt.plot(history.history['accuracy'], label='Eğitim Doğruluğu')\n",
        "plt.plot(history.history['val_accuracy'], label='Doğrulama Doğruluğu')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Doğruluk')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'], label='Eğitim Kaybı')\n",
        "plt.plot(history.history['val_loss'], label='Doğrulama Kaybı')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Kaybı')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "dCuihedUMv6R",
        "outputId": "aed162c4-583e-49cd-ddaa-a0abaae60380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 82 images belonging to 7 classes.\n",
            "Found 19 images belonging to 7 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'validation_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-baba4bfa6696>\u001b[0m in \u001b[0;36m<cell line: 68>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Doğrulama verisini belirtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'validation_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Veri yolunu ayarlayın\n",
        "data_dir = output_folder  # PNG dosyalarının bulunduğu yol\n",
        "classes = ['normal', 'kitle', 'kalsifikasyon']\n",
        "\n",
        "# ImageDataGenerator kullanarak veri ön işleme\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    validation_split=0.2  # %80 eğitim, %20 doğrulama için\n",
        ")\n",
        "\n",
        "# Eğitim verileri\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Doğrulama verileri\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Modeli tanımlayın\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')  # 3 sınıf: normal, kitle, kalsifikasyon\n",
        "])\n",
        "\n",
        "# Modeli derle\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Veri artırma ve ön işleme\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "validation_generator = test_datagen.flow_from_directory(validation_data_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "# Modeli kaydedin\n",
        "model.save('/content/drive/MyDrive/Tekno/11.06-derleme.h5')\n",
        "\n",
        "# Eğitimin tarihçesini görselleştirin\n",
        "plt.plot(history.history['accuracy'], label='Eğitim Doğruluğu')\n",
        "plt.plot(history.history['val_accuracy'], label='Doğrulama Doğruluğu')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Doğruluk')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(history.history['loss'], label='Eğitim Kaybı')\n",
        "plt.plot(history.history['val_loss'], label='Doğrulama Kaybı')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Kaybı')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "hvyW2foiSpDx",
        "outputId": "00823c06-f2f8-4313-8b4a-d1ecfdff7a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 82 images belonging to 7 classes.\n",
            "Found 19 images belonging to 7 classes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_data_dir' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-4d546416ffb3>\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mtest_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_datagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0mvalidation_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_datagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_from_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Modeli kaydedin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data_dir' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Veri yolu\n",
        "train_data_dir = '/content/drive/MyDrive/Tekno'\n",
        "validation_data_dir = '/content/drive/MyDrive/Tekno'\n",
        "\n",
        "# Modeli tanımla\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Modeli derle\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Veri artırma ve ön işleme\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Veri yükleyici\n",
        "train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "validation_generator = test_datagen.flow_from_directory(validation_data_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')\n",
        "\n",
        "# Modeli eğit\n",
        "history = model.fit(train_generator, steps_per_epoch=len(train_generator), epochs=10, validation_data=validation_generator, validation_steps=len(validation_generator))\n",
        "\n",
        "# Eğitim ve doğrulama doğruluklarını görselleştir\n",
        "plt.plot(history.history['accuracy'], label='Eğitim Doğruluğu')\n",
        "plt.plot(history.history['val_accuracy'], label='Doğrulama Doğruluğu')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Doğruluk')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ev92ZjeXQru7",
        "outputId": "d8372f2c-00f6-47ef-dc7b-1ae9d182d2cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 11 images belonging to 6 classes.\n",
            "Found 11 images belonging to 6 classes.\n"
          ]
        }
      ]
    }
  ]
}